{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9184fe3e",
   "metadata": {},
   "source": [
    "### TASK 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf648f2e",
   "metadata": {},
   "source": [
    "### 1) Precision increases when you make fewer false positives, i.e., fewer non-depressed students being classified as depressed.\n",
    "###  Recall increases when you make fewer false negatives, i.e., more depressed students being correctly classified as depressed.\n",
    "### Lowering the threshold increases recall but may hurt precision (more false positives). Raising the threshold improves precision but may reduce recall (more false negatives). The goal is to find a balance between these two metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to compute metrics at different thresholds\n",
    "def compute_metrics_at_thresholds(y_true, y_pred_prob, thresholds):\n",
    "    metrics = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        metrics.append({\n",
    "            'Threshold': threshold,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "            'TN': tn, 'FP': fp, 'FN': fn, 'TP': tp\n",
    "        })\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# Define a range of thresholds (0 to 1 in steps of 0.01)\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "\n",
    "# Get the predicted probabilities\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Compute metrics for each threshold\n",
    "metrics_df = compute_metrics_at_thresholds(y_test, y_pred_prob, thresholds)\n",
    "\n",
    "# Show the first few rows\n",
    "metrics_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
