{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86eb8f2",
   "metadata": {},
   "source": [
    "# Week 3 — Practical Coding Exercise (Constant Model & MSE)\n",
    "This notebook follows the Week 3 instructions:\n",
    "- Generate synthetic data `Y`.\n",
    "- Try a range of constants `c` and compute the MSE for each.\n",
    "- Find the optimal `c` and compare it with the dataset mean.\n",
    "- Plot MSE vs. `c` and mark the optimum.\n",
    "- Reflect on the shape of the curve and the role of a dummy model.\n",
    "- **Bonus:** implement a simple `train_test_split` with shuffling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d58490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make outputs reproducible\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593875d",
   "metadata": {},
   "source": [
    "## 1) Generate synthetic data `Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c800a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the distribution if you want to experiment:\n",
    "# Example A: Normal distribution\n",
    "n = 300\n",
    "Y = rng.normal(loc=4.0, scale=2.0, size=n)\n",
    "\n",
    "# Example B (uncomment to try): Skewed (exponential) distribution\n",
    "# Y = rng.exponential(scale=2.0, size=n)\n",
    "\n",
    "# Quick sanity check\n",
    "print(f\"n = {Y.size}, mean(Y) ≈ {Y.mean():.4f}, std(Y) ≈ {Y.std(ddof=0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac8348",
   "metadata": {},
   "source": [
    "## 2) Grid of constants `c` and MSE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of constants to test\n",
    "c_grid = np.linspace(0, 10, 201)  # 0, 0.05, ..., 10\n",
    "\n",
    "# Compute MSE for each c (vectorized)\n",
    "# MSE(c) = (1/n) * sum_i (Y_i - c)^2\n",
    "mse_values = ((Y[:, None] - c_grid[None, :])**2).mean(axis=0)\n",
    "\n",
    "# Find the best c (minimum MSE)\n",
    "best_idx = np.argmin(mse_values)\n",
    "c_star = c_grid[best_idx]\n",
    "print(f\"Best c on the grid: c* = {c_star:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b4ac8",
   "metadata": {},
   "source": [
    "## 3) Compare optimal `c` with the mean of `Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc402dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = Y.mean()\n",
    "print(f\"Mean of Y: {y_mean:.6f}\")\n",
    "print(f\"Difference |c* - mean(Y)| = {abs(c_star - y_mean):.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83650c30",
   "metadata": {},
   "source": [
    "## 4) Plot MSE vs. `c` and mark the optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26bee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(c_grid, mse_values)\n",
    "plt.axvline(c_star)  # best c\n",
    "plt.title(\"MSE vs. c (constant model)\")\n",
    "plt.xlabel(\"c\")\n",
    "plt.ylabel(\"MSE(c)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8745ec3",
   "metadata": {},
   "source": [
    "## 5) Interpretation\n",
    "- The MSE curve is **convex** (parabolic) in `c`.  \n",
    "- The minimum occurs at **`c = mean(Y)`**. Moving away from the mean increases squared distances, so the MSE grows symmetrically around the mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a6b837",
   "metadata": {},
   "source": [
    "## 6) Why a simple dummy model can be useful\n",
    "- It gives a **baseline** to compare complex models against (sanity check).\n",
    "- It is **fast, stable, and interpretable**.\n",
    "- If a sophisticated model can't beat this baseline, there may be data/feature/label issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d64aa2",
   "metadata": {},
   "source": [
    "## Bonus: Simple `train_test_split` implementation with shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2, rng=None):\n",
    "    \"\"\"Split X, y into train and test using shuffling.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like of shape (n_samples, n_features)\n",
    "    y : array-like of shape (n_samples,)\n",
    "    test_size : float in (0,1)\n",
    "    rng : numpy.random.Generator or None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    assert X.shape[0] == y.shape[0], \"X and y must have the same number of samples\"\n",
    "    n = X.shape[0]\n",
    "    n_test = int(np.floor(test_size * n))\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    perm = rng.permutation(n)\n",
    "    test_idx = perm[:n_test]\n",
    "    train_idx = perm[n_test:]\n",
    "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "# Example use (toy data)\n",
    "X = np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "y = np.array([0,1,0,1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, rng=rng)\n",
    "print(\"X_train:\\n\", X_train)\n",
    "print(\"X_test:\\n\", X_test)\n",
    "print(\"y_train:\", y_train)\n",
    "print(\"y_test:\", y_test)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}